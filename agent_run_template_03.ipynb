{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "rcParams['figure.figsize'] = 10, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.linear_observer_planter import LinearPlanterObserver\n",
    "from env.env_naive_torus import NaiveSandbox\n",
    "from loss.losses import sum_loss_l1\n",
    "from model.a2c import *\n",
    "from reward.rewards import AliveCellsReward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probs_to_cells(probs, env, topk=3):\n",
    "    probs_top_k, idx_top_k = probs.topk(topk)\n",
    "    inserted_block = np.zeros(env.shape)\n",
    "    inserted_block = inserted_block.flatten()\n",
    "    inserted_block[idx_top_k] = 1\n",
    "    return inserted_block.reshape(env.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ActorCritic(100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 3e-3\n",
    "N_GAMES = 2000\n",
    "\n",
    "optimizer = optim.Adam(agent.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_loss = agent.reflect(np.random.rand(10, 1000),list(range(10)), list(range(10)), list(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer.zero_grad()\n",
    "# total_loss.backward()\n",
    "# nn.utils.clip_grad_norm_(agent.parameters(), 0.5)\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size=(10,10)\n",
    "agent_window_size = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandbox = NaiveSandbox(grid_size=grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_loss = []\n",
    "# dummy reward_f\n",
    "from reward.rewards import AliveCellsReward\n",
    "reward_f = AliveCellsReward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "steps_after_action = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(perception_field, env_state, render_agent=True):\n",
    "    clear_output(wait=True)\n",
    "    if render_agent:\n",
    "        plt.imshow(perception_field)\n",
    "        plt.show()\n",
    "    #print('field after agent inference')\n",
    "    #plt.imshow(env_state['grid'])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "x0, y0 = 0, 0\n",
    "steps_after_action = 10\n",
    "N_GAMES = 20\n",
    "N_CELLS = 10\n",
    "state = sandbox.get_grid()\n",
    "from time import sleep\n",
    "\n",
    "for game in range(N_GAMES):\n",
    "    states, actions, rewards, dones = [], [], [], []\n",
    "    for i in range(iterations):\n",
    "        probs = agent.get_action_probs(torch.tensor(sandbox.get_grid()).float().flatten())\n",
    "        perception_field = probs_to_cells(probs.detach(), sandbox.get_grid(), N_CELLS)\n",
    "        env_state = sandbox.forward(inserted_block=perception_field, \n",
    "                                    inserted_block_position_x0=x0, \n",
    "                                    inserted_block_position_y0=y0, \n",
    "                                    n_steps=steps_after_action,\n",
    "                                    reward_fn=reward_f \n",
    "                                   )\n",
    "        next_state, reward, done = env_state['grid'], env_state['reward'], env_state['done']\n",
    "        states.append(state.flatten()); actions.append(perception_field); rewards.append(reward); dones.append(done)\n",
    "        \n",
    "        state = next_state\n",
    "        render(perception_field, env_state, render_agent=True)\n",
    "    total_loss = agent.reflect(states, actions, rewards, dones)\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    print (total_loss.item())\n",
    "    nn.utils.clip_grad_norm_(agent.parameters(), 0.5)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
